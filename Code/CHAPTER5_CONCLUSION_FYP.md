4.8 FINAL GUI AND IMPLEMENTATION

The final user interface for the CEO Decision Support Assistant is shown in Figure 4.8. This Gradio-based GUI enables users to submit both text and image queries, view chat history, and receive grounded, transparent answers. The left panel displays recent chats and allows users to review previous queries, supporting session-based memory. The central panel provides an input box for questions and optional image uploads, with a dropdown to select the LLM model. The right panel presents the system’s answer, including executive summaries, rankings, summary statistics, and suggested follow-up questions. Tool transparency is enhanced by showing the selected route, model, filters, evidence row count, and latency for each response. This design supports auditability and user trust by making all decision steps visible.

The interface implements deterministic routing for KPI queries, reducing numeric hallucination by ensuring structured questions are handled by the correct pipeline. Error handling and refusal behavior are integrated, with the system declining to answer if evidence is insufficient. The GUI’s clear layout and transparency features directly address the reliability and auditability goals outlined in Chapter 3. Figure 4.8 illustrates a typical session, highlighting the system’s ability to deliver grounded, explainable answers for CEO-level decision support.

![Final CEO Assistant GUI](../images/fyp_figures/figure_4_8_final_gui.png)

Figure 4.8: Final user interface of the CEO Decision Support Assistant, showing chat history, input options, and transparent output with tool details. (Caption at bottom as required)
# In the era of rapid digital transformation, effective access to company knowledge has become a critical requirement for decision-makers. This project introduces a prototype AI personal assistant tailored specifically for C-level executives, such as Chief Executive Officers (CEOs), who require instant, reliable access to organizational data without relying on intermediaries. The assistant is powered by a Vision-Language Retrieval-Augmented Generation (VL-RAG) framework that combines image understanding and natural language generation capabilities, enabling it to interpret visual and textual inputs and generate accurate, context-rich responses. The core architecture integrates a vision-language model (BLIP-2) with a large language model (LLaMA 3 – 7B), augmented by a retrieval mechanism (FAISS) that indexes company data from diverse formats including Excel sheets, CSV files, and internal documents. The pipeline involves data preprocessing, semantic chunking, vector embedding, and similarity-based retrieval, followed by prompt-based response generation using the LLM. By leveraging multimodal data processing, the assistant can answer queries related to sales performance, inventory status, marketing strategies, and human resource allocation based on real company datasets. This system was evaluated using predefined query scenarios reflecting real-world executive needs. Quantitative metrics such as retrieval accuracy and response latency were analyzed alongside qualitative assessments of response relevance and coherence. Preliminary results indicate high accuracy and response quality, validating the system’s capacity to serve as a reliable tool for executive decision-making. This research demonstrates the viability of a multimodal AI assistant in enhancing operational efficiency, reducing dependency on human intermediaries, and enabling informed strategic planning. The prototype also sets a foundation for future enterprise-level deployments where adaptive, vision-language-powered agents can streamline access to internal knowledge, transforming the way business leaders interact with corporate data.

\section*{ACKNOWLEDGMENT}

In the name of Allah, the Most Gracious, the Most Merciful. By the grace of Allah SWT, I have successfully completed this Final Year Project, "AI Personal Assistant Using Visual Language Retrieval Augmented Generation." Every opportunity, experience, and challenge overcome is a testament to His blessings and a step towards creating positive change.

I would like to express my sincere gratitude to Assoc. Prof. Abdul Halim Embong, my supervisor, for his invaluable guidance and mentorship throughout this project. His expertise, feedback, and encouragement have been instrumental to my academic and personal growth.

My appreciation also goes to the lecturers of Universiti Teknologi Malaysia for their dedication to teaching and for inspiring curiosity and critical thinking. Special thanks to my family for their unwavering support and sacrifices, and to my friends for their encouragement and companionship during this journey.
